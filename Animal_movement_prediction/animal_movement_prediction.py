# -*- coding: utf-8 -*-
"""animal_movement_prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1O4HnuT4sN-YzhxfqFREylB_kZHlcZ05j

**Predictive Animal Movement Modeling and Early Warning System**

Install Required Libraries
"""

# Install necessary libraries
!pip install pandas numpy matplotlib seaborn scikit-learn tensorflow

# Import libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, classification_report
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, LSTM, Dropout

"""Load and Preprocess Data"""

# Upload dataset
from google.colab import files
uploaded = files.upload()

# Load the dataset
data = pd.read_csv("movement_predictions.csv")

# Inspect the data
print(data.head())

print(data.info())

# Check for missing values
print(data.isnull().sum())

# Fill or drop missing values
data.fillna(method='ffill', inplace=True)  # Forward fill

# Convert timestamp to datetime and extract useful features
data['Timestamps'] = pd.to_datetime(data['Timestamps'])
data['Hour'] = data['Timestamps'].dt.hour
data['Day'] = data['Timestamps'].dt.day

# Convert categorical columns to numerical values
data = pd.get_dummies(data, columns=['Sensor_ID', 'Device_Used', 'Animal_Category', 'Action_Triggered'], drop_first=True)

"""Normalize Data"""

from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()
scaled_data = scaler.fit_transform(data.drop(['Timestamps', 'Animal_path'], axis=1))

"""Prepare Data for Model"""

# Define features (X) and target (y)
X = scaled_data
y = data['Animal_path']  # Replace with the specific column to predict

# Split into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

"""Train LSTM Model"""

# Reshape data for LSTM input
X_train_lstm = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))
X_test_lstm = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))

# Build the LSTM model
model = Sequential()
model.add(LSTM(50, return_sequences=True, input_shape=(X_train_lstm.shape[1], 1)))
model.add(Dropout(0.2))
model.add(LSTM(50, return_sequences=False))
model.add(Dropout(0.2))
model.add(Dense(1))  # Adjust output layer based on y

# Compile the model
model.compile(optimizer='adam', loss='mean_squared_error')

# Check if all elements in X_train are numeric
import numpy as np

# Check data type of X_train and X_test
print(f"X_train data type: {type(X_train)}")
print(f"X_test data type: {type(X_test)}")

# Check if X_train contains any non-numeric columns (if it's a structured array)
if isinstance(X_train, np.ndarray):
    print("Check if any columns are non-numeric (in X_train):")
    print(np.issubdtype(X_train.dtype, np.number))  # Check if the entire array is numeric

# Convert X_train and X_test to numeric (if they are not already)
X_train = np.array(X_train, dtype=np.float32)
X_test = np.array(X_test, dtype=np.float32)

# Reshape for LSTM (if not reshaped already)
X_train_lstm = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))
X_test_lstm = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))

# Check the first few entries in y_train and y_test
print("First few values in y_train:", y_train.head())
print("First few values in y_test:", y_test.head())

from sklearn.preprocessing import MultiLabelBinarizer

# Split the labels (e.g., '2005, 1009' => ['2005', '1009'])
y_train_split = y_train.apply(lambda x: x.split(', '))
y_test_split = y_test.apply(lambda x: x.split(', '))

# Initialize MultiLabelBinarizer to encode the labels
mlb = MultiLabelBinarizer()

# Fit and transform the labels
y_train_encoded = mlb.fit_transform(y_train_split)
y_test_encoded = mlb.transform(y_test_split)

# Check the shape of the encoded labels
print("Encoded y_train shape:", y_train_encoded.shape)
print("Encoded y_test shape:", y_test_encoded.shape)

# If the labels are supposed to be continuous values, convert them to numeric
y_train_clean = pd.to_numeric(y_train, errors='coerce')
y_test_clean = pd.to_numeric(y_test, errors='coerce')

# Check if there are any NaN values (if conversion failed)
print("NaN values in y_train:", y_train_clean.isna().sum())
print("NaN values in y_test:", y_test_clean.isna().sum())

# Optionally, fill NaN values if needed
y_train_clean = y_train_clean.fillna(0)  # Or use another imputation method
y_test_clean = y_test_clean.fillna(0)

# Now, y_train_clean and y_test_clean should be numeric

from keras.callbacks import EarlyStopping

# Define EarlyStopping callback
early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)

history = model.fit(X_train_lstm, y_train_encoded, epochs=20, batch_size=32, validation_data=(X_test_lstm, y_test_encoded), callbacks=[early_stop])

from sklearn.preprocessing import MinMaxScaler

# Apply MinMaxScaler to normalize the data
scaler = MinMaxScaler()

# Scale the input data
X_train_scaled = scaler.fit_transform(X_train.reshape(-1, X_train.shape[1]))
X_test_scaled = scaler.transform(X_test.reshape(-1, X_test.shape[1]))

# Reshape for LSTM (samples, timesteps, features)
X_train_lstm = X_train_scaled.reshape(X_train.shape[0], X_train.shape[1], 1)
X_test_lstm = X_test_scaled.reshape(X_test.shape[0], X_test.shape[1], 1)

"""Define the Model and EarlyStopping Callback"""

from keras.models import Sequential
from keras.layers import LSTM, Dropout, Dense
from keras.callbacks import EarlyStopping

# Define the model
model = Sequential()
model.add(LSTM(50, return_sequences=True, input_shape=(X_train_lstm.shape[1], X_train_lstm.shape[2])))
model.add(Dropout(0.2))
model.add(LSTM(50, return_sequences=False))
model.add(Dropout(0.2))
model.add(Dense(1))  # Single output for regression (no activation function)

# Compile the model
model.compile(optimizer='adam', loss='mean_squared_error')

# EarlyStopping callback
early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)

"""Train the Model"""

history = model.fit(X_train_lstm, y_train_encoded, epochs=20, batch_size=32, validation_data=(X_test_lstm, y_test_encoded), callbacks=[early_stop])

"""Monitor Training and Evaluate Performance"""

import matplotlib.pyplot as plt

# Plot training & validation loss
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.legend()
plt.show()

"""Evaluate the Model and Make Predictions"""

# Evaluate the model on the test set
test_loss = model.evaluate(X_test_lstm, y_test_encoded)
print(f"Test Loss: {test_loss}")

# Make predictions on the test set
predictions = model.predict(X_test_lstm)